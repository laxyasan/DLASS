{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlyXsM-TL4rP",
      "metadata": {
        "id": "SlyXsM-TL4rP"
      },
      "outputs": [],
      "source": [
        "# a. Data Preparation\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
        "import numpy as np\n",
        "#for building CBOW model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
        "\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "auKmZ0plL4rP",
      "metadata": {
        "id": "auKmZ0plL4rP"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"Natural Language Processing is a field of Artificial Intelligence.\",\n",
        "    \"Word embeddings help computers understand human language.\",\n",
        "    \"The CBOW model is a part of Word2Vec technique.\",\n",
        "    \"CBOW predicts the target word using surrounding context words.\",\n",
        "    \"Skip Gram is another architecture of Word2Vec.\",\n",
        "    \"Word2Vec is widely used in NLP applications.\",\n",
        "    \"Embedding layers in deep learning are used to represent words.\",\n",
        "    \"CBOW is faster and works better with frequent words.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iM_HkBEDL4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM_HkBEDL4rQ",
        "outputId": "b3a426af-3861-4b53-a2c2-633003227cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 50\n",
            "Sample Vocabulary: [('is', 1), ('of', 2), ('cbow', 3), ('word2vec', 4), ('words', 5), ('language', 6), ('a', 7), ('word', 8), ('the', 9), ('used', 10)]\n"
          ]
        }
      ],
      "source": [
        "#Tokenize and build vocabulary\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "word2id = tokenizer.word_index\n",
        "word2id['PAD'] = 0   # padding token\n",
        "id2word = {v: k for k, v in word2id.items()}\n",
        "\n",
        "# Convert sentences into sequences of IDs\n",
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in data]\n",
        "\n",
        "vocab_size = len(word2id)\n",
        "embed_size = 100\n",
        "window_size = 2  # context window size\n",
        "\n",
        "print(\"Vocabulary Size:\", vocab_size)\n",
        "print(\"Sample Vocabulary:\", list(word2id.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1YXk2Yl8L4rQ",
      "metadata": {
        "id": "1YXk2Yl8L4rQ"
      },
      "outputs": [],
      "source": [
        "# Generate training data (context -> target)\n",
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "    context_length = window_size * 2\n",
        "    for words in corpus:\n",
        "        sentence_length = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            context_words = []\n",
        "            label_word = []\n",
        "            start = index - window_size\n",
        "            end = index + window_size + 1\n",
        "\n",
        "            # pick context (excluding target word)\n",
        "            context_words.append([words[i]\n",
        "                                  for i in range(start, end)\n",
        "                                  if 0 <= i < sentence_length and i != index])\n",
        "            label_word.append(word)\n",
        "\n",
        "            # pad context & one-hot target\n",
        "            x = pad_sequences(context_words, maxlen=context_length)\n",
        "            y = to_categorical(label_word, vocab_size)\n",
        "            yield (x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HDZgeGAEL4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDZgeGAEL4rQ",
        "outputId": "871f5659-a5d9-4f17-f8f3-4f42a48e9744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context (X): ['natural', 'language', 'is', 'a'] -> Target (Y): processing\n",
            "Context (X): ['language', 'processing', 'a', 'field'] -> Target (Y): is\n",
            "Context (X): ['processing', 'is', 'field', 'of'] -> Target (Y): a\n",
            "Context (X): ['is', 'a', 'of', 'artificial'] -> Target (Y): field\n",
            "Context (X): ['a', 'field', 'artificial', 'intelligence'] -> Target (Y): of\n"
          ]
        }
      ],
      "source": [
        "# Show few examples\n",
        "i = 0\n",
        "for x, y in generate_context_word_pairs(wids, window_size, vocab_size):\n",
        "    if 0 not in x[0]:  # skip padded ones\n",
        "        print(\"Context (X):\", [id2word[w] for w in x[0]], \"-> Target (Y):\", id2word[np.argmax(y[0])])\n",
        "        i += 1\n",
        "        if i == 5:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k9gBeT2XL4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "k9gBeT2XL4rQ",
        "outputId": "e2b9b4b7-d558-4293-e275-ad929c69c343"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │         \u001b[38;5;34m5,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,050</span> (39.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,050\u001b[0m (39.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,050</span> (39.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,050\u001b[0m (39.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "#Build CBOW model\n",
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_shape=(window_size*2,)))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
        "cbow.add(Dense(vocab_size, activation=\"softmax\"))\n",
        "cbow.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "print(cbow.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eFhKx4EL4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eFhKx4EL4rQ",
        "outputId": "26b9f5fd-c018-413e-ee1b-1d639ec84625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 Loss: 262.29654\n",
            "Epoch: 2 Loss: 261.1473\n",
            "Epoch: 3 Loss: 259.29797\n",
            "Epoch: 4 Loss: 257.23203\n",
            "Epoch: 5 Loss: 254.8435\n",
            "Epoch: 6 Loss: 252.0664\n",
            "Epoch: 7 Loss: 248.87202\n",
            "Epoch: 8 Loss: 245.26855\n",
            "Epoch: 9 Loss: 241.29422\n"
          ]
        }
      ],
      "source": [
        "#Train Model\n",
        "for epoch in range(1, 10):  # run fewer epochs for demo\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(wids, window_size, vocab_size):\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        i += 1\n",
        "    print(\"Epoch:\", epoch, \"Loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kf5gRQ3hL4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "kf5gRQ3hL4rQ",
        "outputId": "165e3fcb-e789-43e2-cf61-24c161070ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(49, 100)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-80b12201-06f5-4a79-bfbf-a1506677003b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>-0.112843</td>\n",
              "      <td>-0.076374</td>\n",
              "      <td>0.103728</td>\n",
              "      <td>-0.074037</td>\n",
              "      <td>0.022961</td>\n",
              "      <td>0.229079</td>\n",
              "      <td>0.081067</td>\n",
              "      <td>0.232911</td>\n",
              "      <td>-0.130624</td>\n",
              "      <td>-0.044777</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123222</td>\n",
              "      <td>0.002553</td>\n",
              "      <td>0.136428</td>\n",
              "      <td>0.101167</td>\n",
              "      <td>-0.101709</td>\n",
              "      <td>0.059215</td>\n",
              "      <td>0.126466</td>\n",
              "      <td>-0.022190</td>\n",
              "      <td>0.153879</td>\n",
              "      <td>-0.110381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cbow</th>\n",
              "      <td>-0.106229</td>\n",
              "      <td>-0.044315</td>\n",
              "      <td>-0.026503</td>\n",
              "      <td>-0.217257</td>\n",
              "      <td>0.089675</td>\n",
              "      <td>0.126166</td>\n",
              "      <td>0.194157</td>\n",
              "      <td>-0.002080</td>\n",
              "      <td>0.026144</td>\n",
              "      <td>-0.100506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034981</td>\n",
              "      <td>0.016064</td>\n",
              "      <td>0.132949</td>\n",
              "      <td>0.129231</td>\n",
              "      <td>-0.107518</td>\n",
              "      <td>0.199874</td>\n",
              "      <td>-0.053173</td>\n",
              "      <td>0.159456</td>\n",
              "      <td>0.060617</td>\n",
              "      <td>0.035335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word2vec</th>\n",
              "      <td>-0.065577</td>\n",
              "      <td>-0.092740</td>\n",
              "      <td>-0.073537</td>\n",
              "      <td>0.057295</td>\n",
              "      <td>-0.084892</td>\n",
              "      <td>0.138809</td>\n",
              "      <td>-0.062212</td>\n",
              "      <td>0.196231</td>\n",
              "      <td>-0.194890</td>\n",
              "      <td>-0.083713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138474</td>\n",
              "      <td>0.005089</td>\n",
              "      <td>-0.123522</td>\n",
              "      <td>0.070336</td>\n",
              "      <td>-0.006558</td>\n",
              "      <td>-0.037518</td>\n",
              "      <td>-0.077625</td>\n",
              "      <td>-0.062837</td>\n",
              "      <td>-0.108105</td>\n",
              "      <td>-0.168468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>words</th>\n",
              "      <td>-0.032096</td>\n",
              "      <td>0.073591</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>-0.039886</td>\n",
              "      <td>0.181010</td>\n",
              "      <td>-0.055978</td>\n",
              "      <td>0.191558</td>\n",
              "      <td>-0.063688</td>\n",
              "      <td>-0.028680</td>\n",
              "      <td>-0.100517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.157514</td>\n",
              "      <td>0.150699</td>\n",
              "      <td>-0.045216</td>\n",
              "      <td>0.091428</td>\n",
              "      <td>0.097726</td>\n",
              "      <td>-0.052283</td>\n",
              "      <td>0.008223</td>\n",
              "      <td>0.035641</td>\n",
              "      <td>0.031830</td>\n",
              "      <td>-0.151587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <td>-0.099747</td>\n",
              "      <td>0.151102</td>\n",
              "      <td>-0.151527</td>\n",
              "      <td>0.132460</td>\n",
              "      <td>-0.023889</td>\n",
              "      <td>-0.040634</td>\n",
              "      <td>0.111453</td>\n",
              "      <td>-0.116119</td>\n",
              "      <td>0.043751</td>\n",
              "      <td>-0.034269</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023968</td>\n",
              "      <td>-0.076894</td>\n",
              "      <td>-0.154938</td>\n",
              "      <td>-0.100190</td>\n",
              "      <td>0.103279</td>\n",
              "      <td>0.001107</td>\n",
              "      <td>-0.104661</td>\n",
              "      <td>0.011534</td>\n",
              "      <td>-0.149296</td>\n",
              "      <td>-0.041034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b12201-06f5-4a79-bfbf-a1506677003b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80b12201-06f5-4a79-bfbf-a1506677003b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80b12201-06f5-4a79-bfbf-a1506677003b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e6c46b8a-36fc-4d78-b0f5-a87903411b7d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6c46b8a-36fc-4d78-b0f5-a87903411b7d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e6c46b8a-36fc-4d78-b0f5-a87903411b7d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                0         1         2         3         4         5   \\\n",
              "of       -0.112843 -0.076374  0.103728 -0.074037  0.022961  0.229079   \n",
              "cbow     -0.106229 -0.044315 -0.026503 -0.217257  0.089675  0.126166   \n",
              "word2vec -0.065577 -0.092740 -0.073537  0.057295 -0.084892  0.138809   \n",
              "words    -0.032096  0.073591  0.012096 -0.039886  0.181010 -0.055978   \n",
              "language -0.099747  0.151102 -0.151527  0.132460 -0.023889 -0.040634   \n",
              "\n",
              "                6         7         8         9   ...        90        91  \\\n",
              "of        0.081067  0.232911 -0.130624 -0.044777  ...  0.123222  0.002553   \n",
              "cbow      0.194157 -0.002080  0.026144 -0.100506  ...  0.034981  0.016064   \n",
              "word2vec -0.062212  0.196231 -0.194890 -0.083713  ...  0.138474  0.005089   \n",
              "words     0.191558 -0.063688 -0.028680 -0.100517  ...  0.157514  0.150699   \n",
              "language  0.111453 -0.116119  0.043751 -0.034269  ...  0.023968 -0.076894   \n",
              "\n",
              "                92        93        94        95        96        97  \\\n",
              "of        0.136428  0.101167 -0.101709  0.059215  0.126466 -0.022190   \n",
              "cbow      0.132949  0.129231 -0.107518  0.199874 -0.053173  0.159456   \n",
              "word2vec -0.123522  0.070336 -0.006558 -0.037518 -0.077625 -0.062837   \n",
              "words    -0.045216  0.091428  0.097726 -0.052283  0.008223  0.035641   \n",
              "language -0.154938 -0.100190  0.103279  0.001107 -0.104661  0.011534   \n",
              "\n",
              "                98        99  \n",
              "of        0.153879 -0.110381  \n",
              "cbow      0.060617  0.035335  \n",
              "word2vec -0.108105 -0.168468  \n",
              "words     0.031830 -0.151587  \n",
              "language -0.149296 -0.041034  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Save trained word embeddings to a file\n",
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wb_t9qi0L4rQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb_t9qi0L4rQ",
        "outputId": "e19d290e-b2f1-413d-cc3c-80c1e2f69d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similar Words: {'deep': ['embedding', 'used', 'learning', 'applications', 'in'], 'cbow': ['model', 'skip', 'gram', 'part', 'target']}\n"
          ]
        }
      ],
      "source": [
        "#Find similar words using Euclidean distance\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "\n",
        "similar_words = {\n",
        "    search: [id2word[idx] for idx in distance_matrix[word2id[search]-1].argsort()[1:6]+1]\n",
        "    for search in [\"deep\", \"cbow\"]\n",
        "}\n",
        "\n",
        "print(\"Similar Words:\", similar_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
